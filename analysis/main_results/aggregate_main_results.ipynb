{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import os\n",
    "\n",
    "# Third-party library imports\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "TASK = (\"code_translation\", \"code_repair\", \"assert_generation\")\n",
    "NAME_MAPPING = {\n",
    "    \"codet5p-220m\": \"CodeT5+ 220M\",\n",
    "    \"codet5p-770m\": \"CodeT5+ 770M\"\n",
    "}\n",
    "RENAME_TUNING_METHOD_DICT = {\n",
    "    \"full-finetuning\": \"Full Fine-Tuning\",\n",
    "    \"no-gnn\": \"Linear Adapter\",\n",
    "    \"concatpervector\": \"Transducers Tuning\",\n",
    "    \"lora\": \"LoRA\",\n",
    "    \"prompt-tuning\": \"Prompt-Tuning\",\n",
    "    \"prefix-tuning\": \"Prefix-Tuning\",\n",
    "    \"no-finetuning\": \"No Fine-Tuning\"\n",
    "}\n",
    "\n",
    "SEEDS = (\"seed_18_1\", \"seed_99_1\")\n",
    "DATASET_BASEPATH = \"/data/datasets/fix/\"\n",
    "\n",
    "RENAME_COLUMNS = {\n",
    "    \"model\": \"Model\",\n",
    "    \"tuning_method\": \"Tuning Method\",\n",
    "\n",
    "    \"assert_generation_mean\": \"Assert Generation\",\n",
    "    \"assert_generation_std\": \"Assert Generation (std)\",\n",
    "    \n",
    "    \"code_translation_mean\": \"Code Translation\",\n",
    "    \"code_translation_std\": \"Code Translation (std)\",\n",
    "    \n",
    "    \"code_repair_mean\": \"Code Repair\",\n",
    "    \"code_repair_std\": \"Code Repair (std)\",\n",
    "\n",
    "    \"summarization_mean\": \"Summarization\",\n",
    "    \"summarization_std\": \"Summarization (std)\",\n",
    "\n",
    "    \"average\": \"Average\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['code_translation/codet5p-220m_prompt-tuning.csv',\n",
       " 'code_translation/codet5p-220m_concatpervector.csv',\n",
       " 'code_translation/codet5p-770m_full-finetuning.csv',\n",
       " 'code_translation/codet5p-770m_lora.csv',\n",
       " 'code_translation/codet5p-220m_prefix-tuning.csv']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def read_csv(root_path: str)->list:\n",
    "    output_paths = []\n",
    "    for filename in os.listdir(root_path):\n",
    "        filepath = os.path.join(root_path, filename)\n",
    "        output_paths.append(filepath)\n",
    "    return output_paths\n",
    "\n",
    "output_paths = []\n",
    "for task in TASK:\n",
    "    output_paths += read_csv(task)\n",
    "output_paths[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df(paths: list)->pd.DataFrame:\n",
    "    temp_list = []\n",
    "    for path in paths:\n",
    "        if \"ipynb_checkpoints\" not in path:\n",
    "            filename = os.path.basename(path)\n",
    "            filename = filename.split(\"_\")\n",
    "            model = filename[0]\n",
    "            if model in NAME_MAPPING.keys():\n",
    "                \n",
    "                df = pd.read_csv(path)\n",
    "\n",
    "                task = path.split(\"/\")[0]\n",
    "                df[\"task\"] = task\n",
    "\n",
    "                # filter seed and similar ids\n",
    "                temp_task = task if task != \"code_repair\" else \"code_repair_long\"\n",
    "                ids_path = os.path.join(DATASET_BASEPATH, f\"{temp_task}/included_ids.csv\")\n",
    "                included_ids = pd.read_csv(ids_path)\n",
    "                mask_ids = df[\"idx.1\"].isin(included_ids[\"idx\"])\n",
    "                mask_seed = df[\"seed\"].isin(SEEDS)\n",
    "                df = df[(mask_seed) & (mask_ids)].copy()\n",
    "                df[\"model\"] = model\n",
    "\n",
    "                tuning_method = os.path.splitext(filename[1])[0]\n",
    "                df[\"tuning_method\"] = tuning_method\n",
    "\n",
    "                if task != \"summarization\":\n",
    "                    # df.drop(columns=[\"codebleu_stat\"], inplace=True)\n",
    "                    df = df[[\"model\", \"tuning_method\", \"task\", \"seed\", \"codebleu-cn\"]].copy()\n",
    "                else:\n",
    "                    df = df[[\"model\", \"tuning_method\", \"task\",  \"seed\", \"bleu-cn\"]].copy().round(2)\n",
    "\n",
    "                temp_list.append(df)\n",
    "\n",
    "    df = pd.concat(temp_list)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = create_df(output_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>tuning_method</th>\n",
       "      <th>assert_generation_mean</th>\n",
       "      <th>assert_generation_std</th>\n",
       "      <th>code_translation_mean</th>\n",
       "      <th>code_translation_std</th>\n",
       "      <th>code_repair_mean</th>\n",
       "      <th>code_repair_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>codet5p-220m</td>\n",
       "      <td>concatpervector</td>\n",
       "      <td>82.32</td>\n",
       "      <td>0.30</td>\n",
       "      <td>96.60</td>\n",
       "      <td>1.31</td>\n",
       "      <td>98.10</td>\n",
       "      <td>0.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>codet5p-220m</td>\n",
       "      <td>full-finetuning</td>\n",
       "      <td>83.16</td>\n",
       "      <td>0.01</td>\n",
       "      <td>97.78</td>\n",
       "      <td>0.00</td>\n",
       "      <td>99.87</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>codet5p-220m</td>\n",
       "      <td>lora</td>\n",
       "      <td>83.17</td>\n",
       "      <td>0.00</td>\n",
       "      <td>97.78</td>\n",
       "      <td>0.00</td>\n",
       "      <td>99.87</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>codet5p-220m</td>\n",
       "      <td>no-finetuning</td>\n",
       "      <td>76.85</td>\n",
       "      <td>0.00</td>\n",
       "      <td>94.47</td>\n",
       "      <td>0.00</td>\n",
       "      <td>96.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>codet5p-220m</td>\n",
       "      <td>no-gnn</td>\n",
       "      <td>82.48</td>\n",
       "      <td>0.02</td>\n",
       "      <td>97.70</td>\n",
       "      <td>0.12</td>\n",
       "      <td>99.31</td>\n",
       "      <td>0.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>codet5p-220m</td>\n",
       "      <td>prefix-tuning</td>\n",
       "      <td>83.17</td>\n",
       "      <td>0.00</td>\n",
       "      <td>97.78</td>\n",
       "      <td>0.00</td>\n",
       "      <td>99.87</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>codet5p-220m</td>\n",
       "      <td>prompt-tuning</td>\n",
       "      <td>83.17</td>\n",
       "      <td>0.00</td>\n",
       "      <td>94.40</td>\n",
       "      <td>0.27</td>\n",
       "      <td>97.46</td>\n",
       "      <td>1.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>codet5p-770m</td>\n",
       "      <td>concatpervector</td>\n",
       "      <td>81.16</td>\n",
       "      <td>0.71</td>\n",
       "      <td>94.88</td>\n",
       "      <td>0.08</td>\n",
       "      <td>96.75</td>\n",
       "      <td>3.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>codet5p-770m</td>\n",
       "      <td>full-finetuning</td>\n",
       "      <td>83.16</td>\n",
       "      <td>0.01</td>\n",
       "      <td>97.78</td>\n",
       "      <td>0.00</td>\n",
       "      <td>99.87</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>codet5p-770m</td>\n",
       "      <td>lora</td>\n",
       "      <td>83.17</td>\n",
       "      <td>0.00</td>\n",
       "      <td>97.78</td>\n",
       "      <td>0.00</td>\n",
       "      <td>99.87</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>codet5p-770m</td>\n",
       "      <td>no-finetuning</td>\n",
       "      <td>74.13</td>\n",
       "      <td>0.00</td>\n",
       "      <td>90.10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>95.71</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>codet5p-770m</td>\n",
       "      <td>no-gnn</td>\n",
       "      <td>81.23</td>\n",
       "      <td>0.88</td>\n",
       "      <td>97.77</td>\n",
       "      <td>0.02</td>\n",
       "      <td>99.82</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>codet5p-770m</td>\n",
       "      <td>prefix-tuning</td>\n",
       "      <td>83.15</td>\n",
       "      <td>0.02</td>\n",
       "      <td>97.78</td>\n",
       "      <td>0.00</td>\n",
       "      <td>99.87</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>codet5p-770m</td>\n",
       "      <td>prompt-tuning</td>\n",
       "      <td>83.17</td>\n",
       "      <td>0.00</td>\n",
       "      <td>90.15</td>\n",
       "      <td>0.01</td>\n",
       "      <td>99.22</td>\n",
       "      <td>0.71</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           model    tuning_method  assert_generation_mean  \\\n",
       "0   codet5p-220m  concatpervector                   82.32   \n",
       "1   codet5p-220m  full-finetuning                   83.16   \n",
       "2   codet5p-220m             lora                   83.17   \n",
       "3   codet5p-220m    no-finetuning                   76.85   \n",
       "4   codet5p-220m           no-gnn                   82.48   \n",
       "5   codet5p-220m    prefix-tuning                   83.17   \n",
       "6   codet5p-220m    prompt-tuning                   83.17   \n",
       "7   codet5p-770m  concatpervector                   81.16   \n",
       "8   codet5p-770m  full-finetuning                   83.16   \n",
       "9   codet5p-770m             lora                   83.17   \n",
       "10  codet5p-770m    no-finetuning                   74.13   \n",
       "11  codet5p-770m           no-gnn                   81.23   \n",
       "12  codet5p-770m    prefix-tuning                   83.15   \n",
       "13  codet5p-770m    prompt-tuning                   83.17   \n",
       "\n",
       "    assert_generation_std  code_translation_mean  code_translation_std  \\\n",
       "0                    0.30                  96.60                  1.31   \n",
       "1                    0.01                  97.78                  0.00   \n",
       "2                    0.00                  97.78                  0.00   \n",
       "3                    0.00                  94.47                  0.00   \n",
       "4                    0.02                  97.70                  0.12   \n",
       "5                    0.00                  97.78                  0.00   \n",
       "6                    0.00                  94.40                  0.27   \n",
       "7                    0.71                  94.88                  0.08   \n",
       "8                    0.01                  97.78                  0.00   \n",
       "9                    0.00                  97.78                  0.00   \n",
       "10                   0.00                  90.10                  0.00   \n",
       "11                   0.88                  97.77                  0.02   \n",
       "12                   0.02                  97.78                  0.00   \n",
       "13                   0.00                  90.15                  0.01   \n",
       "\n",
       "    code_repair_mean  code_repair_std  \n",
       "0              98.10             0.39  \n",
       "1              99.87             0.00  \n",
       "2              99.87             0.00  \n",
       "3              96.00             0.00  \n",
       "4              99.31             0.71  \n",
       "5              99.87             0.00  \n",
       "6              97.46             1.13  \n",
       "7              96.75             3.94  \n",
       "8              99.87             0.00  \n",
       "9              99.87             0.00  \n",
       "10             95.71             0.00  \n",
       "11             99.82             0.02  \n",
       "12             99.87             0.00  \n",
       "13             99.22             0.71  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_df = df.groupby([\"model\", \"tuning_method\", \"task\", \"seed\"], as_index=False).mean()\n",
    "temp_std = temp_df.groupby([\"model\", \"tuning_method\", \"task\"], as_index=False)[\"codebleu-cn\"].std().round(2)\n",
    "\n",
    "df.drop(columns=[\"seed\"], inplace=True)\n",
    "\n",
    "# Calculate the mean and standard deviation for each group\n",
    "temp_mean = df.groupby([\"model\", \"tuning_method\", \"task\"], as_index=False).mean().round(2)\n",
    "\n",
    "# Add a suffix to the columns to distinguish between mean and std\n",
    "temp_mean = temp_mean.add_suffix('_mean')\n",
    "temp_std = temp_std.add_suffix('_std')\n",
    "\n",
    "# Merge mean and std DataFrames\n",
    "temp1 = pd.merge(temp_mean, temp_std, left_on=[\"model_mean\", \"tuning_method_mean\", \"task_mean\"], \n",
    "                         right_on=[\"model_std\", \"tuning_method_std\", \"task_std\"])\n",
    "\n",
    "# Drop redundant columns after merge\n",
    "temp1.drop(columns=[\"model_std\", \"tuning_method_std\", \"task_std\"], inplace=True)\n",
    "\n",
    "# Rename columns for clarity\n",
    "temp1.rename(columns={\"model_mean\": \"model\", \"tuning_method_mean\": \"tuning_method\", \"task_mean\": \"task\"}, inplace=True)\n",
    "\n",
    "# Melt the combined DataFrame to have mean and std in the metrics column\n",
    "temp1 = pd.melt(temp1, \n",
    "                      id_vars=[\"model\", \"tuning_method\", \"task\"], \n",
    "                      var_name=\"metrics\", \n",
    "                      value_name=\"value\")\n",
    "\n",
    "# Pivot the DataFrame to organize tasks as columns and keep both mean and std under the metrics\n",
    "temp1 = temp1.pivot_table(index=['model', 'tuning_method', 'metrics'], \n",
    "                                       columns='task', values='value').reset_index()\n",
    "\n",
    "# Drop the \"metrics\" column if needed or leave it to distinguish between mean and std\n",
    "# temp_pivoted.drop(columns=[\"metrics\"], inplace=True)  # Uncomment if you don't want to keep \"metrics\"\n",
    "\n",
    "# Optional: Clean up column names\n",
    "temp1.columns.name = None\n",
    "\n",
    "# Fill NaN values with 0.0\n",
    "temp1.fillna(0.0, inplace=True)\n",
    "\n",
    "\n",
    "df_mean = temp1[temp1['metrics'].str.contains('_mean')].copy()\n",
    "df_std = temp1[temp1['metrics'].str.contains('_std')].copy()\n",
    "\n",
    "# Remove the '_mean' and '_std' suffixes from the 'metrics' column\n",
    "df_mean['metrics'] = df_mean['metrics'].str.replace('_mean', '')\n",
    "df_std['metrics'] = df_std['metrics'].str.replace('_std', '')\n",
    "\n",
    "# Merge the mean and std DataFrames on 'model', 'tuning_method', and 'metrics'\n",
    "temp1 = pd.merge(df_mean, df_std, on=['model', 'tuning_method', 'metrics'], suffixes=('_mean', '_std'))\n",
    "temp1 = temp1[[\"model\", \"tuning_method\", \"assert_generation_mean\", \"assert_generation_std\", \"code_translation_mean\", \"code_translation_std\", \"code_repair_mean\", \"code_repair_std\"]].copy()\n",
    "temp1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['summarization/codet5p-220m_prompt-tuning.csv',\n",
       " 'summarization/codet5p-220m_concatpervector.csv',\n",
       " 'summarization/codet5p-770m_full-finetuning.csv',\n",
       " 'summarization/codet5p-770m_lora.csv']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_paths = read_csv(\"summarization\")\n",
    "output_paths[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>tuning_method</th>\n",
       "      <th>summarization_mean</th>\n",
       "      <th>summarization_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>codet5p-220m</td>\n",
       "      <td>concatpervector</td>\n",
       "      <td>99.84</td>\n",
       "      <td>0.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>codet5p-220m</td>\n",
       "      <td>full-finetuning</td>\n",
       "      <td>99.91</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>codet5p-220m</td>\n",
       "      <td>lora</td>\n",
       "      <td>99.91</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>codet5p-220m</td>\n",
       "      <td>no-finetuning</td>\n",
       "      <td>95.49</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>codet5p-220m</td>\n",
       "      <td>no-gnn</td>\n",
       "      <td>98.05</td>\n",
       "      <td>0.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>codet5p-220m</td>\n",
       "      <td>prefix-tuning</td>\n",
       "      <td>99.93</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>codet5p-220m</td>\n",
       "      <td>prompt-tuning</td>\n",
       "      <td>99.91</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>codet5p-770m</td>\n",
       "      <td>concatpervector</td>\n",
       "      <td>98.11</td>\n",
       "      <td>1.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>codet5p-770m</td>\n",
       "      <td>full-finetuning</td>\n",
       "      <td>99.81</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>codet5p-770m</td>\n",
       "      <td>lora</td>\n",
       "      <td>99.79</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>codet5p-770m</td>\n",
       "      <td>no-finetuning</td>\n",
       "      <td>87.90</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>codet5p-770m</td>\n",
       "      <td>no-gnn</td>\n",
       "      <td>98.24</td>\n",
       "      <td>1.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>codet5p-770m</td>\n",
       "      <td>prefix-tuning</td>\n",
       "      <td>99.85</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>codet5p-770m</td>\n",
       "      <td>prompt-tuning</td>\n",
       "      <td>99.82</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           model    tuning_method  summarization_mean  summarization_std\n",
       "0   codet5p-220m  concatpervector               99.84               0.21\n",
       "1   codet5p-220m  full-finetuning               99.91               0.01\n",
       "2   codet5p-220m             lora               99.91               0.00\n",
       "3   codet5p-220m    no-finetuning               95.49               0.00\n",
       "4   codet5p-220m           no-gnn               98.05               0.88\n",
       "5   codet5p-220m    prefix-tuning               99.93               0.01\n",
       "6   codet5p-220m    prompt-tuning               99.91               0.01\n",
       "7   codet5p-770m  concatpervector               98.11               1.61\n",
       "8   codet5p-770m  full-finetuning               99.81               0.01\n",
       "9   codet5p-770m             lora               99.79               0.02\n",
       "10  codet5p-770m    no-finetuning               87.90               0.00\n",
       "11  codet5p-770m           no-gnn               98.24               1.39\n",
       "12  codet5p-770m    prefix-tuning               99.85               0.00\n",
       "13  codet5p-770m    prompt-tuning               99.82               0.01"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = create_df(output_paths)\n",
    "\n",
    "temp_df = df.groupby([\"model\", \"tuning_method\", \"task\", \"seed\"], as_index=False).mean()\n",
    "temp_std = temp_df.groupby([\"model\", \"tuning_method\", \"task\"], as_index=False)[\"bleu-cn\"].std().round(2)\n",
    "\n",
    "df.drop(columns=[\"seed\"], inplace=True)\n",
    "\n",
    "# Calculate the mean and standard deviation for each group\n",
    "temp_mean = df.groupby([\"model\", \"tuning_method\", \"task\"], as_index=False).mean().round(2)\n",
    "\n",
    "# Add a suffix to the columns to distinguish between mean and std\n",
    "temp_mean = temp_mean.add_suffix('_mean')\n",
    "temp_std = temp_std.add_suffix('_std')\n",
    "\n",
    "# Merge mean and std DataFrames\n",
    "temp2 = pd.merge(temp_mean, temp_std, left_on=[\"model_mean\", \"tuning_method_mean\", \"task_mean\"], \n",
    "                         right_on=[\"model_std\", \"tuning_method_std\", \"task_std\"])\n",
    "\n",
    "# Drop redundant columns after merge\n",
    "temp2.drop(columns=[\"model_std\", \"tuning_method_std\", \"task_std\"], inplace=True)\n",
    "\n",
    "# Rename columns for clarity\n",
    "temp2.rename(columns={\"model_mean\": \"model\", \"tuning_method_mean\": \"tuning_method\", \"task_mean\": \"task\"}, inplace=True)\n",
    "\n",
    "# Melt the combined DataFrame to have mean and std in the metrics column\n",
    "temp2 = pd.melt(temp2, \n",
    "                      id_vars=[\"model\", \"tuning_method\", \"task\"], \n",
    "                      var_name=\"metrics\", \n",
    "                      value_name=\"value\")\n",
    "\n",
    "# Pivot the DataFrame to organize tasks as columns and keep both mean and std under the metrics\n",
    "temp2 = temp2.pivot_table(index=['model', 'tuning_method', 'metrics'], \n",
    "                                       columns='task', values='value').reset_index()\n",
    "\n",
    "# Drop the \"metrics\" column if needed or leave it to distinguish between mean and std\n",
    "# temp_pivoted.drop(columns=[\"metrics\"], inplace=True)  # Uncomment if you don't want to keep \"metrics\"\n",
    "\n",
    "# Optional: Clean up column names\n",
    "temp2.columns.name = None\n",
    "\n",
    "# Fill NaN values with 0.0\n",
    "temp2.fillna(0.0, inplace=True)\n",
    "\n",
    "df_mean = temp2[temp2['metrics'].str.contains('_mean')].copy()\n",
    "df_std = temp2[temp2['metrics'].str.contains('_std')].copy()\n",
    "\n",
    "# Remove the '_mean' and '_std' suffixes from the 'metrics' column\n",
    "df_mean['metrics'] = df_mean['metrics'].str.replace('_mean', '')\n",
    "df_std['metrics'] = df_std['metrics'].str.replace('_std', '')\n",
    "\n",
    "# Merge the mean and std DataFrames on 'model', 'tuning_method', and 'metrics'\n",
    "temp2 = pd.merge(df_mean, df_std, on=['model', 'tuning_method', 'metrics'], suffixes=('_mean', '_std'))\n",
    "temp2 = temp2[[\"model\", \"tuning_method\", \"summarization_mean\", \"summarization_std\"]].copy()\n",
    "temp2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Tuning Method</th>\n",
       "      <th>Summarization</th>\n",
       "      <th>Summarization (std)</th>\n",
       "      <th>Assert Generation</th>\n",
       "      <th>Assert Generation (std)</th>\n",
       "      <th>Code Translation</th>\n",
       "      <th>Code Translation (std)</th>\n",
       "      <th>Code Repair</th>\n",
       "      <th>Code Repair (std)</th>\n",
       "      <th>Average</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>codet5p-220m</td>\n",
       "      <td>Transducers Tuning</td>\n",
       "      <td>99.84</td>\n",
       "      <td>0.21</td>\n",
       "      <td>82.32</td>\n",
       "      <td>0.30</td>\n",
       "      <td>96.60</td>\n",
       "      <td>1.31</td>\n",
       "      <td>98.10</td>\n",
       "      <td>0.39</td>\n",
       "      <td>94.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>codet5p-220m</td>\n",
       "      <td>Full Fine-Tuning</td>\n",
       "      <td>99.91</td>\n",
       "      <td>0.01</td>\n",
       "      <td>83.16</td>\n",
       "      <td>0.01</td>\n",
       "      <td>97.78</td>\n",
       "      <td>0.00</td>\n",
       "      <td>99.87</td>\n",
       "      <td>0.00</td>\n",
       "      <td>95.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>codet5p-220m</td>\n",
       "      <td>LoRA</td>\n",
       "      <td>99.91</td>\n",
       "      <td>0.00</td>\n",
       "      <td>83.17</td>\n",
       "      <td>0.00</td>\n",
       "      <td>97.78</td>\n",
       "      <td>0.00</td>\n",
       "      <td>99.87</td>\n",
       "      <td>0.00</td>\n",
       "      <td>95.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>codet5p-220m</td>\n",
       "      <td>No Fine-Tuning</td>\n",
       "      <td>95.49</td>\n",
       "      <td>0.00</td>\n",
       "      <td>76.85</td>\n",
       "      <td>0.00</td>\n",
       "      <td>94.47</td>\n",
       "      <td>0.00</td>\n",
       "      <td>96.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>90.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>codet5p-220m</td>\n",
       "      <td>Linear Adapter</td>\n",
       "      <td>98.05</td>\n",
       "      <td>0.88</td>\n",
       "      <td>82.48</td>\n",
       "      <td>0.02</td>\n",
       "      <td>97.70</td>\n",
       "      <td>0.12</td>\n",
       "      <td>99.31</td>\n",
       "      <td>0.71</td>\n",
       "      <td>94.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>codet5p-220m</td>\n",
       "      <td>Prefix-Tuning</td>\n",
       "      <td>99.93</td>\n",
       "      <td>0.01</td>\n",
       "      <td>83.17</td>\n",
       "      <td>0.00</td>\n",
       "      <td>97.78</td>\n",
       "      <td>0.00</td>\n",
       "      <td>99.87</td>\n",
       "      <td>0.00</td>\n",
       "      <td>95.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>codet5p-220m</td>\n",
       "      <td>Prompt-Tuning</td>\n",
       "      <td>99.91</td>\n",
       "      <td>0.01</td>\n",
       "      <td>83.17</td>\n",
       "      <td>0.00</td>\n",
       "      <td>94.40</td>\n",
       "      <td>0.27</td>\n",
       "      <td>97.46</td>\n",
       "      <td>1.13</td>\n",
       "      <td>93.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>codet5p-770m</td>\n",
       "      <td>Transducers Tuning</td>\n",
       "      <td>98.11</td>\n",
       "      <td>1.61</td>\n",
       "      <td>81.16</td>\n",
       "      <td>0.71</td>\n",
       "      <td>94.88</td>\n",
       "      <td>0.08</td>\n",
       "      <td>96.75</td>\n",
       "      <td>3.94</td>\n",
       "      <td>92.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>codet5p-770m</td>\n",
       "      <td>Full Fine-Tuning</td>\n",
       "      <td>99.81</td>\n",
       "      <td>0.01</td>\n",
       "      <td>83.16</td>\n",
       "      <td>0.01</td>\n",
       "      <td>97.78</td>\n",
       "      <td>0.00</td>\n",
       "      <td>99.87</td>\n",
       "      <td>0.00</td>\n",
       "      <td>95.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>codet5p-770m</td>\n",
       "      <td>LoRA</td>\n",
       "      <td>99.79</td>\n",
       "      <td>0.02</td>\n",
       "      <td>83.17</td>\n",
       "      <td>0.00</td>\n",
       "      <td>97.78</td>\n",
       "      <td>0.00</td>\n",
       "      <td>99.87</td>\n",
       "      <td>0.00</td>\n",
       "      <td>95.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>codet5p-770m</td>\n",
       "      <td>No Fine-Tuning</td>\n",
       "      <td>87.90</td>\n",
       "      <td>0.00</td>\n",
       "      <td>74.13</td>\n",
       "      <td>0.00</td>\n",
       "      <td>90.10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>95.71</td>\n",
       "      <td>0.00</td>\n",
       "      <td>86.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>codet5p-770m</td>\n",
       "      <td>Linear Adapter</td>\n",
       "      <td>98.24</td>\n",
       "      <td>1.39</td>\n",
       "      <td>81.23</td>\n",
       "      <td>0.88</td>\n",
       "      <td>97.77</td>\n",
       "      <td>0.02</td>\n",
       "      <td>99.82</td>\n",
       "      <td>0.02</td>\n",
       "      <td>94.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>codet5p-770m</td>\n",
       "      <td>Prefix-Tuning</td>\n",
       "      <td>99.85</td>\n",
       "      <td>0.00</td>\n",
       "      <td>83.15</td>\n",
       "      <td>0.02</td>\n",
       "      <td>97.78</td>\n",
       "      <td>0.00</td>\n",
       "      <td>99.87</td>\n",
       "      <td>0.00</td>\n",
       "      <td>95.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>codet5p-770m</td>\n",
       "      <td>Prompt-Tuning</td>\n",
       "      <td>99.82</td>\n",
       "      <td>0.01</td>\n",
       "      <td>83.17</td>\n",
       "      <td>0.00</td>\n",
       "      <td>90.15</td>\n",
       "      <td>0.01</td>\n",
       "      <td>99.22</td>\n",
       "      <td>0.71</td>\n",
       "      <td>93.09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Model       Tuning Method  Summarization  Summarization (std)  \\\n",
       "0   codet5p-220m  Transducers Tuning          99.84                 0.21   \n",
       "1   codet5p-220m    Full Fine-Tuning          99.91                 0.01   \n",
       "2   codet5p-220m                LoRA          99.91                 0.00   \n",
       "3   codet5p-220m      No Fine-Tuning          95.49                 0.00   \n",
       "4   codet5p-220m      Linear Adapter          98.05                 0.88   \n",
       "5   codet5p-220m       Prefix-Tuning          99.93                 0.01   \n",
       "6   codet5p-220m       Prompt-Tuning          99.91                 0.01   \n",
       "7   codet5p-770m  Transducers Tuning          98.11                 1.61   \n",
       "8   codet5p-770m    Full Fine-Tuning          99.81                 0.01   \n",
       "9   codet5p-770m                LoRA          99.79                 0.02   \n",
       "10  codet5p-770m      No Fine-Tuning          87.90                 0.00   \n",
       "11  codet5p-770m      Linear Adapter          98.24                 1.39   \n",
       "12  codet5p-770m       Prefix-Tuning          99.85                 0.00   \n",
       "13  codet5p-770m       Prompt-Tuning          99.82                 0.01   \n",
       "\n",
       "    Assert Generation  Assert Generation (std)  Code Translation  \\\n",
       "0               82.32                     0.30             96.60   \n",
       "1               83.16                     0.01             97.78   \n",
       "2               83.17                     0.00             97.78   \n",
       "3               76.85                     0.00             94.47   \n",
       "4               82.48                     0.02             97.70   \n",
       "5               83.17                     0.00             97.78   \n",
       "6               83.17                     0.00             94.40   \n",
       "7               81.16                     0.71             94.88   \n",
       "8               83.16                     0.01             97.78   \n",
       "9               83.17                     0.00             97.78   \n",
       "10              74.13                     0.00             90.10   \n",
       "11              81.23                     0.88             97.77   \n",
       "12              83.15                     0.02             97.78   \n",
       "13              83.17                     0.00             90.15   \n",
       "\n",
       "    Code Translation (std)  Code Repair  Code Repair (std)  Average  \n",
       "0                     1.31        98.10               0.39    94.22  \n",
       "1                     0.00        99.87               0.00    95.18  \n",
       "2                     0.00        99.87               0.00    95.18  \n",
       "3                     0.00        96.00               0.00    90.70  \n",
       "4                     0.12        99.31               0.71    94.38  \n",
       "5                     0.00        99.87               0.00    95.19  \n",
       "6                     0.27        97.46               1.13    93.73  \n",
       "7                     0.08        96.75               3.94    92.72  \n",
       "8                     0.00        99.87               0.00    95.16  \n",
       "9                     0.00        99.87               0.00    95.15  \n",
       "10                    0.00        95.71               0.00    86.96  \n",
       "11                    0.02        99.82               0.02    94.26  \n",
       "12                    0.00        99.87               0.00    95.16  \n",
       "13                    0.01        99.22               0.71    93.09  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merge = pd.merge(temp2, temp1, on=[\"model\", \"tuning_method\"])\n",
    "merge['average'] = merge[['assert_generation_mean', 'code_repair_mean', 'code_translation_mean', 'summarization_mean']].mean(axis=1).round(2)\n",
    "merge[\"tuning_method\"] = merge[\"tuning_method\"].apply(lambda x: RENAME_TUNING_METHOD_DICT[x])\n",
    "merge.rename(columns=RENAME_COLUMNS, inplace=True)\n",
    "merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge.to_csv(\"table_1.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
