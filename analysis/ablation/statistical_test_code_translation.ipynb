{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from pingouin import wilcoxon\n",
    "from tqdm import tqdm\n",
    "# Initialize tqdm for pandas\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TASK = \"code_translation\"\n",
    "NAME_MAPPING = {\n",
    "    \"codet5p-220m\": \"CodeT5+ 220M\",\n",
    "    \"codet5p-770m\": \"CodeT5+ 770M\"\n",
    "}\n",
    "RENAME_TUNING_METHOD_DICT = {\n",
    "    \"full-finetuning\": \"Full Fine-Tuning\",\n",
    "    \"no-gnn\": \"Linear Adapter\",\n",
    "    \"concatpervector\": \"GVE + ABF\",\n",
    "    \"lora\": \"LoRA\",\n",
    "    \"prompt-tuning\": \"Prompt-Tuning\",\n",
    "    \"prefix-tuning\": \"Prefix-Tuning\",\n",
    "    \"no-finetuning\": \"No Fine-Tuning\",\n",
    "    \"concatpervector_linear\": \"Linear\",\n",
    "    \"concatpervector_no_gve\": \"No GVE\",\n",
    "    \"concatpervector_no_abf\": \"No ABF\"\n",
    "}\n",
    "\n",
    "SEEDS = (\"seed_18_1\", \"seed_99_1\")\n",
    "DATASET_BASEPATH = \"/data/datasets/fix/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['code_translation/codet5p-770m_concatpervector_no_gve.csv',\n",
       " 'code_translation/codet5p-220m_concatpervector_no_gve.csv',\n",
       " 'code_translation/codet5p-220m_concatpervector.csv',\n",
       " 'code_translation/codet5p-770m_concatpervector_no_abf.csv',\n",
       " 'code_translation/codet5p-770m_concatpervector.csv']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def read_csv(root_path: str)->list:\n",
    "    output_paths = []\n",
    "    for filename in os.listdir(root_path):\n",
    "        filepath = os.path.join(root_path, filename)\n",
    "        output_paths.append(filepath)\n",
    "    return output_paths\n",
    "\n",
    "output_paths = read_csv(TASK)\n",
    "output_paths[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df(paths: list)->pd.DataFrame:\n",
    "    temp_list = []\n",
    "    for path in paths:\n",
    "        if \"ipynb_checkpoints\" not in path:\n",
    "            filename = os.path.basename(path)\n",
    "            model = filename.split(\"_\")\n",
    "            model = model[0]\n",
    "            if model in NAME_MAPPING.keys():\n",
    "                \n",
    "                df = pd.read_csv(path)\n",
    "\n",
    "                task = path.split(\"/\")[0]\n",
    "                df[\"task\"] = task\n",
    "\n",
    "                # filter seed and similar ids\n",
    "                temp_task = task if task != \"code_repair\" else \"code_repair_long\"\n",
    "                ids_path = os.path.join(DATASET_BASEPATH, f\"{temp_task}/included_ids.csv\")\n",
    "                included_ids = pd.read_csv(ids_path)\n",
    "                mask_ids = df[\"idx.1\"].isin(included_ids[\"idx\"])\n",
    "                mask_seed = df[\"seed\"].isin(SEEDS)\n",
    "                df = df[(mask_seed) & (mask_ids)].copy()\n",
    "                df[\"model\"] = model\n",
    "\n",
    "                tuning_method = \"_\".join(os.path.splitext(filename)[0].split(\"_\")[1:])\n",
    "                df[\"tuning_method\"] = tuning_method\n",
    "\n",
    "                if task != \"summarization\":\n",
    "                    # df.drop(columns=[\"codebleu_stat\"], inplace=True)\n",
    "                    df = df[[\"model\", \"tuning_method\", \"task\", \"seed\", \"codebleu-cn\"]].copy()\n",
    "                    df.rename(columns={\"codebleu-cn\":\"codebleu\"}, inplace=True)\n",
    "                else:\n",
    "                    df = df[[\"model\", \"tuning_method\", \"task\",  \"seed\", \"bleu-cn\"]].copy().round(2)\n",
    "\n",
    "                temp_list.append(df)\n",
    "\n",
    "    df = pd.concat(temp_list)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>backbone_model</th>\n",
       "      <th>tuning_method</th>\n",
       "      <th>codebleu_mean</th>\n",
       "      <th>codebleu_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>codet5p-220m</td>\n",
       "      <td>GVE + ABF</td>\n",
       "      <td>96.60</td>\n",
       "      <td>1.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>codet5p-220m</td>\n",
       "      <td>Linear</td>\n",
       "      <td>91.76</td>\n",
       "      <td>0.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>codet5p-220m</td>\n",
       "      <td>No ABF</td>\n",
       "      <td>96.03</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>codet5p-220m</td>\n",
       "      <td>No GVE</td>\n",
       "      <td>92.53</td>\n",
       "      <td>2.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>codet5p-770m</td>\n",
       "      <td>GVE + ABF</td>\n",
       "      <td>94.88</td>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>codet5p-770m</td>\n",
       "      <td>Linear</td>\n",
       "      <td>90.40</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>codet5p-770m</td>\n",
       "      <td>No ABF</td>\n",
       "      <td>97.78</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>codet5p-770m</td>\n",
       "      <td>No GVE</td>\n",
       "      <td>91.11</td>\n",
       "      <td>0.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  backbone_model tuning_method  codebleu_mean  codebleu_std\n",
       "0   codet5p-220m     GVE + ABF          96.60          1.31\n",
       "1   codet5p-220m        Linear          91.76          0.36\n",
       "2   codet5p-220m        No ABF          96.03          0.00\n",
       "3   codet5p-220m        No GVE          92.53          2.65\n",
       "4   codet5p-770m     GVE + ABF          94.88          0.08\n",
       "5   codet5p-770m        Linear          90.40          0.02\n",
       "6   codet5p-770m        No ABF          97.78          0.00\n",
       "7   codet5p-770m        No GVE          91.11          0.33"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = create_df(output_paths)\n",
    "\n",
    "temp_df = df.groupby([\"model\", \"tuning_method\", \"task\", \"seed\"], as_index=False).mean()\n",
    "temp_std = temp_df.groupby([\"model\", \"tuning_method\", \"task\"], as_index=False)[\"codebleu\"].std().round(2)\n",
    "\n",
    "df.drop(columns=[\"seed\"], inplace=True)\n",
    "\n",
    "# Calculate the mean and standard deviation for each group\n",
    "temp_mean = df.groupby([\"model\", \"tuning_method\", \"task\"], as_index=False).mean().round(2)\n",
    "\n",
    "# Add a suffix to the columns to distinguish between mean and std\n",
    "temp_mean = temp_mean.add_suffix('_mean')\n",
    "temp_std = temp_std.add_suffix('_std')\n",
    "\n",
    "# Merge mean and std DataFrames\n",
    "df_metric = pd.merge(temp_mean, temp_std, left_on=[\"model_mean\", \"tuning_method_mean\", \"task_mean\"], \n",
    "                         right_on=[\"model_std\", \"tuning_method_std\", \"task_std\"])\n",
    "\n",
    "# Drop redundant columns after merge\n",
    "df_metric.drop(columns=[\"model_std\", \"tuning_method_std\", \"task_std\", \"task_mean\"], inplace=True)\n",
    "\n",
    "# Rename columns for clarity\n",
    "df_metric.rename(columns={\"model_mean\": \"backbone_model\", \"tuning_method_mean\": \"tuning_method\"} , inplace=True)\n",
    "df_metric[\"tuning_method\"] = df_metric[\"tuning_method\"].apply(lambda x: RENAME_TUNING_METHOD_DICT[x])\n",
    "\n",
    "\n",
    "df_metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform Statistical Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['code_translation/codet5p-770m_concatpervector_no_gve.csv',\n",
       " 'code_translation/codet5p-220m_concatpervector_no_gve.csv',\n",
       " 'code_translation/codet5p-220m_concatpervector.csv',\n",
       " 'code_translation/codet5p-770m_concatpervector_no_abf.csv',\n",
       " 'code_translation/codet5p-770m_concatpervector.csv',\n",
       " 'code_translation/codet5p-220m_concatpervector_no_abf.csv',\n",
       " 'code_translation/codet5p-770m_concatpervector_linear.csv',\n",
       " 'code_translation/codet5p-220m_concatpervector_linear.csv']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def read_csv(root_path: str)->list:\n",
    "    output_paths = []\n",
    "    for filename in os.listdir(root_path):\n",
    "        filepath = os.path.join(root_path, filename)\n",
    "        output_paths.append(filepath)\n",
    "    return output_paths\n",
    "\n",
    "output_paths = read_csv(TASK)\n",
    "output_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dict_for_stat_test(paths: list)->pd.DataFrame:\n",
    "    gaft_dict = {}\n",
    "    baseline_dict = {}\n",
    "    for path in paths:\n",
    "        if \"ipynb_checkpoints\" not in path:\n",
    "            filename = os.path.basename(path)\n",
    "            backbone_model = filename.split(\"_\")[0]\n",
    "            tuning_method = \"_\".join(os.path.splitext(filename)[0].split(\"_\")[1:])\n",
    "    \n",
    "            df = pd.read_csv(path)\n",
    "\n",
    "            # filter seed and similar ids\n",
    "            temp_task = TASK if TASK != \"code_repair\" else \"code_repair_long\"\n",
    "            ids_path = os.path.join(DATASET_BASEPATH, f\"{temp_task}/included_ids.csv\")\n",
    "            included_ids = pd.read_csv(ids_path)\n",
    "            mask_ids = df[\"idx.1\"].isin(included_ids[\"idx\"])\n",
    "            mask_seed = df[\"seed\"].isin(SEEDS)\n",
    "            df = df[(mask_seed) & (mask_ids)].copy()\n",
    "            if tuning_method == \"concatpervector\":\n",
    "                if backbone_model not in gaft_dict:\n",
    "                    gaft_dict[backbone_model] = {}\n",
    "                gaft_dict[backbone_model][tuning_method] = df\n",
    "            else:\n",
    "                if backbone_model not in baseline_dict:\n",
    "                    baseline_dict[backbone_model] = {}\n",
    "                baseline_dict[backbone_model][tuning_method] = df\n",
    "    return gaft_dict, baseline_dict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "gaft_dict, baseline_dict = create_dict_for_stat_test(output_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('public virtual ListReusableDelegationSetsResponse ListReusableDelegationSets(ListReusableDelegationSetsRequest request){var options = new InvokeOptions();options.RequestMarshaller = ListReusableDelegationSetsRequestMarshaller.Instance;options.ResponseUnmarshaller = ListReusableDelegationSetsResponseUnmarshaller.Instance;return Invoke<ListReusableDelegationSetsResponse>(request, options);}\\n\\npublic virtual ListReusableDelegationSetResponse ListReusableDelegationSet(ListReusableDelegationSetRequest request){var options = new InvokeOptions();options.RequestMarshaller = ListReusableDelegationSetRequestMarshaller.Instance;options.ResponseUnmarshaller = ListReusableDelegationSetResponseUnmarshaller.Instance;return Invoke<ListReusableDelegationSetResponse>(request, options);}',\n",
       " 'public virtual ListReusableDelegationSetsResponse ListReusableDelegationSets(ListReusableDelegationSetsRequest request){var options = new InvokeOptions();options.RequestMarshaller = ListReusableDelegationSetsRequestMarshaller.Instance;options.ResponseUnmarshaller = ListReusableDelegationSetsResponseUnmarshaller.Instance;return Invoke<ListReusableDelegationSetsResponse>(request, options);}')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = gaft_dict[\"codet5p-770m\"][\"concatpervector\"]\n",
    "idx = 0\n",
    "temp[temp[\"bleu-cn\"] < 100].iloc[idx].preds, temp[temp[\"bleu-cn\"] < 100].iloc[idx].labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_wilcoxon_test(gaft_dict, baseline_dict, metric_name):\n",
    "    p_val_dict = {}\n",
    "    r_val_dict = {}\n",
    "    for backbone_model, tuning_method_dict in baseline_dict.items():\n",
    "        df_reference = gaft_dict[backbone_model][\"concatpervector\"]\n",
    "        group1 = df_reference[metric_name].to_list()\n",
    "        p_val_dict[backbone_model] = {}\n",
    "        r_val_dict[backbone_model] = {}\n",
    "        for tuning_method, df_baseline in tuning_method_dict.items():    \n",
    "            group2 = df_baseline[metric_name].to_list()\n",
    "            assert len(group1) == len(group2)\n",
    "            print(f\"Performing test | {len(group1)} samples | {backbone_model} | concatpervector vs {tuning_method}\")\n",
    "\n",
    "            w, alternative, p, rbc, CLES = wilcoxon(group1, group2, **{\"zero_method\": \"zsplit\"}).iloc[0].to_list()\n",
    "\n",
    "            # w, alternative, p = wilcoxon(group1, group2, alternative=\"two-sided\", zero_method=\"zsplit\")\n",
    "            p_val_dict[backbone_model][tuning_method] = p\n",
    "            r_val_dict[backbone_model][tuning_method] = rbc\n",
    "\n",
    "    return p_val_dict, r_val_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME_MAPPING_INVERSE = {v:k for k,v in NAME_MAPPING.items()}\n",
    "RENAME_TUNING_METHOD_INVERSE = {v:k for k,v in RENAME_TUNING_METHOD_DICT.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Full Fine-Tuning': 'full-finetuning',\n",
       " 'Linear Adapter': 'no-gnn',\n",
       " 'GVE + ABF': 'concatpervector',\n",
       " 'LoRA': 'lora',\n",
       " 'Prompt-Tuning': 'prompt-tuning',\n",
       " 'Prefix-Tuning': 'prefix-tuning',\n",
       " 'No Fine-Tuning': 'no-finetuning',\n",
       " 'Linear': 'concatpervector_linear',\n",
       " 'No GVE': 'concatpervector_no_gve',\n",
       " 'No ABF': 'concatpervector_no_abf'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RENAME_TUNING_METHOD_INVERSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_df(df_input, p_val_dict, col_name):\n",
    "    df = df_input.copy()\n",
    "    df[col_name] = 0\n",
    "    for idx, row in df.iterrows():\n",
    "        backbone_model = row[\"backbone_model\"]\n",
    "        tuning_method = RENAME_TUNING_METHOD_INVERSE[row[\"tuning_method\"]]\n",
    "        if tuning_method in p_val_dict.get(backbone_model, {}):\n",
    "            df.at[idx, col_name] = p_val_dict[backbone_model][tuning_method]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing test | 740 samples | codet5p-770m | concatpervector vs concatpervector_no_gve\n",
      "Performing test | 740 samples | codet5p-770m | concatpervector vs concatpervector_no_abf\n",
      "Performing test | 740 samples | codet5p-770m | concatpervector vs concatpervector_linear\n",
      "Performing test | 740 samples | codet5p-220m | concatpervector vs concatpervector_no_gve\n",
      "Performing test | 740 samples | codet5p-220m | concatpervector vs concatpervector_no_abf\n",
      "Performing test | 740 samples | codet5p-220m | concatpervector vs concatpervector_linear\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2250379/1450134502.py:8: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '2.0400797896021106e-07' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[idx, col_name] = p_val_dict[backbone_model][tuning_method]\n",
      "/tmp/ipykernel_2250379/1450134502.py:8: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '0.9474747474747476' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  df.at[idx, col_name] = p_val_dict[backbone_model][tuning_method]\n"
     ]
    }
   ],
   "source": [
    "p_val_dict, r_val_dict = perform_wilcoxon_test(gaft_dict, baseline_dict, \"codebleu-cn\")\n",
    "df_final = combine_df(df_metric, p_val_dict, \"p_val\")\n",
    "df_final = combine_df(df_final, r_val_dict, \"rbc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>backbone_model</th>\n",
       "      <th>tuning_method</th>\n",
       "      <th>codebleu_mean</th>\n",
       "      <th>codebleu_std</th>\n",
       "      <th>p_val</th>\n",
       "      <th>rbc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CodeT5+ 220M</td>\n",
       "      <td>GVE + ABF</td>\n",
       "      <td>96.60</td>\n",
       "      <td>1.31</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CodeT5+ 220M</td>\n",
       "      <td>Linear</td>\n",
       "      <td>91.76</td>\n",
       "      <td>0.36</td>\n",
       "      <td>2.040080e-07</td>\n",
       "      <td>0.947475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CodeT5+ 220M</td>\n",
       "      <td>No ABF</td>\n",
       "      <td>96.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.781153e-02</td>\n",
       "      <td>0.328006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CodeT5+ 220M</td>\n",
       "      <td>No GVE</td>\n",
       "      <td>92.53</td>\n",
       "      <td>2.65</td>\n",
       "      <td>4.963901e-07</td>\n",
       "      <td>0.957021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CodeT5+ 770M</td>\n",
       "      <td>GVE + ABF</td>\n",
       "      <td>94.88</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CodeT5+ 770M</td>\n",
       "      <td>Linear</td>\n",
       "      <td>90.40</td>\n",
       "      <td>0.02</td>\n",
       "      <td>6.290603e-06</td>\n",
       "      <td>0.910740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CodeT5+ 770M</td>\n",
       "      <td>No ABF</td>\n",
       "      <td>97.78</td>\n",
       "      <td>0.00</td>\n",
       "      <td>9.218347e-04</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CodeT5+ 770M</td>\n",
       "      <td>No GVE</td>\n",
       "      <td>91.11</td>\n",
       "      <td>0.33</td>\n",
       "      <td>1.632935e-04</td>\n",
       "      <td>0.871903</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  backbone_model tuning_method  codebleu_mean  codebleu_std         p_val  \\\n",
       "0   CodeT5+ 220M     GVE + ABF          96.60          1.31  0.000000e+00   \n",
       "1   CodeT5+ 220M        Linear          91.76          0.36  2.040080e-07   \n",
       "2   CodeT5+ 220M        No ABF          96.03          0.00  1.781153e-02   \n",
       "3   CodeT5+ 220M        No GVE          92.53          2.65  4.963901e-07   \n",
       "4   CodeT5+ 770M     GVE + ABF          94.88          0.08  0.000000e+00   \n",
       "5   CodeT5+ 770M        Linear          90.40          0.02  6.290603e-06   \n",
       "6   CodeT5+ 770M        No ABF          97.78          0.00  9.218347e-04   \n",
       "7   CodeT5+ 770M        No GVE          91.11          0.33  1.632935e-04   \n",
       "\n",
       "        rbc  \n",
       "0  0.000000  \n",
       "1  0.947475  \n",
       "2  0.328006  \n",
       "3  0.957021  \n",
       "4  0.000000  \n",
       "5  0.910740  \n",
       "6 -1.000000  \n",
       "7  0.871903  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ordering = ['backbone_model', 'tuning_method', \n",
    "            'codebleu_mean', 'codebleu_std','p_val', 'rbc'\n",
    "        ]\n",
    "df_final = df_final[ordering].copy()\n",
    "df_final[\"backbone_model\"] = df_final[\"backbone_model\"].apply(lambda x: NAME_MAPPING[x]) \n",
    "df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.to_csv(f\"t_test_{TASK}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
